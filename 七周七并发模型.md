# 《七周七并发模型》
## 第1章 概述
* 并发、并行的区别
* 并行架构
    1. 位级并行（32位、64位）
    2. 指令级并行（流水线、乱序执行、猜测执行）
    3. 数据级并行（simd）
    4. 任务级并行（多处理器）

## 第2章 线程与锁
```java
public class HelloWorld {
    public static void main(String[] args) throws InterruptedException {
        Thread myThread = new Thread() {
            //实现了Thread接口的run函数
            public void run() {
                System.out.println("Hello from new thread");
            }
        };

        myThread.start();

        //通知调度器：当前线程想要让出对处理器的占用
        Thread.yield();

        System.out.println("Hello from main thread");
        myThread.join();
    }
}
// 运行这段代码的结果可能是
// Hello from main thread
// Hello from new thread
// 也可能是
// Hello from new thread
// Hello from main thread
```

```java
public class Counting {
public static void main(String[] args) throws InterruptedException {
    class Counter {
        private int count = 0;
        public void increment() { ++count; }
        public int getCount() { return count; }
    }

    final Counter counter = new Counter();

    class CountingThread extends Thread {
        public void run() {
        for(int x = 0; x < 10000; ++x)
            counter.increment();
        }
    }
        CountingThread t1 = new CountingThread();
        CountingThread t2 = new CountingThread();
        t1.start(); t2.start();
        t1.join(); t2.join();
        System.out.println(counter.getCount());
    }
}
// 竞态条件
// 运行这段代码，每次都将获得不同的结果
```

```java
class Counter {
    private int count = 0;
    //synchronized（同步化）关键字，加锁（同一时间只有一个线程能够访问，其余线程被阻塞）
    public synchronized void increment() { ++count; }
    public int getCount() { return count; }
}
```

* 多把锁：会引起死锁（哲学家进餐问题）
    * 解决办法：总是按照一个全局的固定的顺序获取多把锁（并不现实、项目一大，加锁的地方就会到处分布）

* 第一天我们学到了什么：
    1. 对共享变量的所有访问都需要同步化；（同步化就是加锁的意思）
    2. 读线程和写线程都需要同步化；（防止竞态）
    3. 按照约定的全局顺序来获取多把锁；（防死锁，哲学家问题）
    4. 当持有锁时避免调用外星方法；（这里的外星方法应该是回调的意思，因为不知道回调里面会不会有死锁条件）
    5. 持有锁的时间应尽可能短。（降低死锁几率、降低阻塞几率）

* 内置锁的限制：
    1. 一个线程因为等待内置锁而进入阻塞之后，就无法中断该线程了；
    2. 尝试获取内置锁时，无法设置超时；
    3. 获得内置锁，必须使用synchronized块。

* ReentrantLock：
```java
Lock lock = new ReentrantLock();
lock.lock();
try {
    // 使用共享资源
} finally {
    lock.unlock();
}
```
* 可中断的锁：
```java
final ReentrantLock l1 = new ReentrantLock();
final ReentrantLock l2 = new ReentrantLock();
Thread t1 = new Thread() {
    public void run() {
        try {
        //可断锁
        l1.lockInterruptibly();
        Thread.sleep(1000);
        //可断锁
        l2.lockInterruptibly();
        } catch (InterruptedException e) { 
            System.out.println("t1 interrupted"); 
        }
    }
};
// Thread.interrupt()可以让线程终止
```
* 超时
```java
final ReentrantLock l1 = new ReentrantLock();
l1.tryLock(1000, TimeUnit.MILLISECONDS);
//这个方案并不能避免死锁——它只是提供了从死锁中恢复的手段
//活锁现象:如果所有死锁线程同时超时，它们极有可能再次陷入死锁(为每个线程设置不同的超时时间可以减小活锁的几率)
//对资源的争夺状况却没有得到任何改善

```

* 按任意顺序获取和释放锁
```java
ReentrantLock lock = new ReentrantLock();
Condition condition = lock.newCondition();
lock.lock();
try {
    //并发编程经常需要等待某个事件发生
    //用await()，它将原子地解锁并阻塞等待该条件
    //当另一个线程调用了signal()或signalAll()，意味着对应的条件可能变为真，
    //await()将原子地恢复运行并重新加锁。
    while (!«条件为真») condition.await();
    // 使用共享资源
} finally { lock.unlock(); }
```


* 原子变量(ReentrantLock外的解决办法)<br>
（貌似是用硬件实现的）<br>
好处：
1. 不会忘了在正确的时候获取锁
2. 没有锁，不会引发死锁
```java
public class Counting {
    public static void main(String[] args) throws InterruptedException {

        //原子性的int
        final AtomicInteger counter = new AtomicInteger();

        class CountingThread extends Thread {
            public void run() {
            for(int x = 0; x < 10000; ++x)
                //等价于++count
                counter.incrementAndGet();
            }
        }

        CountingThread t1 = new CountingThread();
        CountingThread t2 = new CountingThread();
        t1.start(); t2.start();
        t1.join(); t2.join();
        System.out.println(counter.get());
    }
}
```

* 第3天：有一个很好的简单demo来说明了我们之前学到的东西（推荐复习）

* 优缺点
    * 优点：
        1. 适用面很广
        2. 正确使用时，其效率很高
    * 缺点：
        1. 不适用于分布式
        2. 不易察觉的错误
        3. 可维护性（做不了单元测试、就做不了重构）
    

## 第3章 函数式编程
函数式编程没有可变状态，所以不会遇到由共享可变状态带来的种种问题。

* 可变状态的风险：
    1. 隐藏的可变状态：面向对象隐藏了可变状态，无法从API无法判断是否是线程安全。
    2. 逃逸的可变状态：以手动编程提供的线程安全性可能存在漏洞。

* 第一天我们学到了什么：
    1. 用map或mapcat对一个序列的每个元素进行映射；
    2. 用序列的懒惰特性来处理较大的序列，甚至无穷序列；
    3. 用reduce将序列化简为一个（可能比较复杂的）值；
    4. 用fold对reduce进行并行化。(这个可能是这节书唯一成谜的地方)

* fold并行化：
    1. fold使用二分算法对集合进行化简
    2. 被fold的对象需要实现CollFold接口
    3. 不支持懒惰序列（因为惰性不支持二分算法）

* 第二天我们学到了什么：（没学到什么）
    1. pmap可以将映射操作并行化，构造一个半懒惰的map。
    2. 利用partition-all可以对并行的映射操作进行批处理，以提高处理效率。
    3. fold使用分而治之的策略，可以将化简操作并行化。
    4. clojure.core.reducers包提供的类似map、类似mapcat、类似filter的函数返回的并不是序列，而是化简器reducible，可以说这是化简操作的关键所在。<br>
（都没啥用，只有reducible有点意思，是一个类似于高等函数之类的东西）

* 第三天
    1. 引用透明（这个只要是涉及函数式的都会说到）
    2. future、promise这两个东西和js的promise在抽象上一样的东西。<br>
    但是实现上的不同导致clojure的可以进行并行，clojure的promise是每一次对它进行解引用（相当于await）时就会生成一条新线程来完成这个任务，在得到值之前会阻塞该线程


    

## 第4章 Clojure之道——分离标识与状态
* 原子变量（Clojure的原子变量是用java的原子变量实现的）
* 持久数据结构（就是函数式编程不会修改原有的对象，而用各种指针共享数据结构的那一套）
* 标识与状态：如果一个线程引用了持久数据结构，那么其他线程对数据结构的修改对该线程就是不可见的。
* 重试
    1. 当swap!调用其参数函数（即由参数传入的函数）产生新值、但还未修改原子变量的值时，其他线程就修改了原子变量的值。
    2. 如果发生了这种情况，swap!就需要重试（retry）。swap!将放弃从参数函数中返回的值，并用原子变量的新值重新调用参数函数。
    3. 这要求swap!的参数函数必须没有副作用

* 第一天我们学到了什么：
    1. 函数式语言中，数据结构是持久的，也就是说当一个线程修改它时，将不会影响到引用同一个数据结构的其他线程。
    2. 借助上述特性，我们可以分离标识与状态。与标识不同，状态实际上是一系列随时间变化的值。

（这里实在是搞不懂、虽然说其他线程的修改确实是影响不到当前线程、但这不就是生成了多个状态了么？究竟哪个状态才是最终结果？这个一致性问题如何解决？）

* 第二天：代理和软件事务内存
    1. 代理：代理的api和原子变量很相似<br>
    send与swap!的区别是，前者会（在代理的值更新之前）立刻返回（这里说明send的异步操作、还配有await函数等待其执行完成）<br>
    传给send的函数将在之后的某个时间被调用。<br>
    如果多个线程同时调用send，传给send的函数将被串行调用：<br>
    同一时间只会调用一个。也就是说该函数不会进行重试，并且可以具有副作用
        * send: 是用的线程池<br>
        Send-Off:用的新进程<br>
        Send-Via:用指定线程
    2. 软件事务内存：<br>
    通过原子变量和代理每次仅能修改一个变量，<br>
    而通过软件事务内存可以对多个变量进行并发的一致的修改

    * 原子变量可以对单一值进行**隔离的**、**同步的**更新。
    * 代理可以对单一值进行**隔离的**、**异步的**更新。
    * 引用可以对多个值进行**一致的**、**同步的**更新。

* 代理是actor吗？
    1. 通过deref可以获得代理的值，而actor没有提供直接获得值的方式；
    2. actor可以包含行为（behavior），而代理则不可以——对数据的操作函数必须由调用者提供；
    3. actor提供了复杂的错误检测和错误恢复的机制，而代理仅提供了简单的错误报告机制；
    4. actor能支持分布式，而代理则不能；
    5. 使用多个actor可能会引发死锁，而使用多个代理则不会。

* 第三天：总结
    1. 基于STM的解决方案<br>
    （通过事务来达成多个值的一致性）<br>
    可以被<br>
    基于代理的解决方案<br>
    （将多个值整合到一个数据结构中，并用一个代理来管理对这个数据结构的访问）<br>
    替换；
    2. 在两种方案之间的选择往往基于个人风格和程序性能

    * 优点：传统命令式语言的变量混淆了标识与状态这两个概念，而Clojure的持久数据结构将可变量的标识与状态分离开来。这解决了使用锁的方案的大部分缺点
    * 缺点：不支持分布式


    

## 第5章 Actor
* 第一天总结
    * 第一天的例子用js转写：
    ```javascript

    // 用spawn()创建新进程
    const pid = spawn(async function() {
        let v = await this.receive(msg => {
            const [status, value] = msg
            // 通过模式匹配来处理消息；
            if (status === 'hello') return value
            if (status === 'world') return "won't match"
        })

        v = await this.receive()
    })

    // 用send()向进程发送消息；
    pid.send(['hello', 'yes this is dog'])
    pid.send('anything')
    ```

* 第二天总结
    * 连接是双向的——如果进程a连接到进程b，那么进程b也连接到进程a；
    * 连接可以传递错误——如果两个进程已经连接，其中一个进程异常终止，那么另一个进程也会异常终止；
    * 如果进程被转化成系统进程，当其连接的进程异常终止时，系统进程不会终止，而是会收到:EXIT消息

* 第三天：分布式<br>
    这个玩意和zeroMq很像，<br>
    还能直接让远程节点执行函数<br>
    还提供了这些功能：<br>
    * 重启策略
    * 调试与日志
    * 代码热升级
    * 发布管理、故障切换、自动扩容，等等

* 优点
    * 消息传输和封装（也就是面向对象）
    * 容错（管理线程可以把崩溃的线程重新拉起来）
    * 分布式编程
* 缺点
    * 仍会碰到死锁
    * 信箱溢出
    * 多个actor并不共享状态，仅通过消息传递来进行交流，所以不太适合实施细粒度的并行

## 第6章 通信顺序进程
* 第一天：channel和go块
    * Channel： 一个线程安全的队列，可以配置缓存区已满时的策略
    * go块： 类似于js的async函数，返回的总是Channel
    * <!：从Channel里面读取数据的操作符，类似于await
    
* 第二天：多个channel与IO
从第二天的介绍上面看下来这个东西更像是async/await和RX的合体<br>
因为Channel不同于promise，不会用一次就废掉，可以无限往里面填数据和拉数据
    
* 第三天：客户端CSP
通过ClojureScript将代码输出成js在浏览器上执行，<br>
不同的地方是将点击事件转化为一个Channel，避免了回调函数的使用
```clojure
(defn start []
    // 事件转化为一个Channel
    (let [canvas (dom/getElement "canvas")
        graphics (create-graphics canvas)
        clicks (get-events canvas "click")]

        // go块中死循环读取数据
        (go (while true
            (let [click (<! clicks)
                    x (.-offsetX click)
                    y (.-offsetY click)]
                (shrinking-circle graphics x y))))))
(set! (.-onload js/window) start)
```


* 优点：
    * 与actor模型相比，CSP模型的最大的优点是灵活性
* 缺点：
    * 有两个主题没有被提及——分布式和容错性
    * CSP模型也容易受到死锁影响
    * 没有提供直接的并行支持


## 第7章 数据并行
* 第一天：GPGPU编程
* 第二天：多维空间与工作组
* 第三天：OpenCL和OpenGL——全部在GPU上运行

每天一个使用OpenCL实现的用例以说明数据并行的使用方式，要专门学习OpenCL

* 优点：非常适用于处理大量数值数据，尤其适合于科学计算、工程计算以及仿真领域
* 缺点：不适用于所有问题领域


## 第8章 Lambda架构
* 第一天：MapReduce
基本上是将函数式那一套应用到分布式集群上

* 第二天：批处理层
    * 传统数据系统的缺陷：
        * 扩展性
        * 维护成本
        * 复杂度
        * 人为错误
        * 报表与分析（因为没有历史数据）
    * 原始数据及衍生信息（不修改原始数据，在需要的时候可以由原始数据推导出衍生信息）
        * 只处理不可变的原始数据，批处理层可以轻松地被并行化
        * 原始数据可以分布到一个多机集群
        * 不变性也使得系统可以承受住技术性故障和人为故障
            * 原始数据更容易进行备份
            * 如果存在bug，最坏的情况就是批处理视图是暂时错误的
        * 存在着一个严重的问题——延迟

* 第三天：加速层
    1. 有新数据产生时，一方面将其添加到原始数据中，这样批处理层就可以进行处理
    2. 另一方面将其传给加速层
    3. 加速层会生成实时视图，实时视图会和批处理视图合并来满足对最新数据的查询
    4. 当这部分数据被批处理层处理后，该实时视图将被弃用

    * 加速层要比批处理层复杂，最容易想到的构建加速层的方法就是模仿传统的同步数据库
    * 其实可以将传统数据库看作是Lambda架构的一种退化特例（不使用批处理层）


* 优点：
    * Lambda架构主要用于解决大规模数据的问题——这些问题是传统数据处理架构难以应对的
    * Lambda架构非常适合于报表和分析——以前我们会使用数据仓库来进行这类工作
* 缺点：
    * 小数据情况下是杀鸡用牛刀

## 第9章 圆满结束
    * 未来是“不变”的（函数式里面的不变）
    * 未来是分布式的
    * 未尽之路（没有被介绍的技术）
        * Fork/Join模型和Work-Stealing算法
        * 数据流
        * 反应型编程
        * 函数式反应型编程
        * 网格计算
        * 元组空间
